res$figyr
df = mrh_train
feature = 'ZONIER'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
test <- df %>% mutate(REGION = substr(ZONIER, 1,1))
feature = 'REGION'
res<-resume(test, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE1_AN1'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE1_AN2'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE1_AN3'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE2_AN1'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE2_AN2'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE2_AN3'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'ANNEE'
res<-resume(df, feature)
res$table
res$fig
preprocess<- function(dt) {
res <- dt %>%
mutate(
NB_PIECES = ifelse(is.na(NB_PIECES), 2, NB_PIECES), #2 est le mode de NB_PIECES
NBSIN_TYPE1_AN1 = ifelse(NBSIN_TYPE1_AN1==0,0,1), #On regroupe les modalités non stables dans le temps
NBSIN_TYPE1_AN3 = ifelse(NBSIN_TYPE1_AN3==0,0,1), #On regroupe les modalités non stables dans le temps
REGION =  gsub('[0-9]', '', ZONIER) #création de région
) %>%
select(-c('X', 'TYPE_HABITATION', 'NIVEAU_JURIDIQUE', 'NBSIN_TYPE1_AN2', 'NBSIN_TYPE2_AN1', 'NBSIN_TYPE2_AN2', 'NBSIN_TYPE2_AN3'  )) %>% # On supprime les variables sans lien stable dans le temps
relocate('id', 'EXPO', 'FORMULE', 'TYPE_RESIDENCE', 'SITUATION_JURIDIQUE', 'OBJETS_DE_VALEUR', 'VALEUR_DES_BIENS', 'NB_PIECES', 'ZONIER', 'REGION', 'NBSIN_TYPE1_AN1', 'NBSIN_TYPE1_AN3', 'ANNEE', 'NB', 'COUT' )
return(res)
}
df_train <- preprocess(mrh_train)
df_val <- preprocess(mrh_val)
df_test <- preprocess(mrh_test)
X_train <- df_train %>% select(-c('id', 'EXPO', 'NB', 'COUT'))
# Initialize empty matrix to store coefficients
empty_m <- matrix(ncol = length(X_train),
nrow = length(X_train),
dimnames = list(names(X_train),
names(X_train)))
# Function that accepts matrix for coefficients and data and returns a correlation matrix
calculate_cramer <- function(m, df) {
for (r in seq(nrow(m))){
for (c in seq(ncol(m))){
m[[r, c]] <- lsr::cramersV(X_train[[r]], X_train[[c]])
}
}
return(m)
}
cor_matrix <- calculate_cramer(empty_m ,X_train)
corrplot(cor_matrix)
reg0 = glm(NB~1+offset(log(EXPO)),family=poisson,data=df_train)
summary(reg0)
plot(reg0)
reg0 = glm(NB~1+offset(log(EXPO)),family=poisson,data=df_train)
summary(reg0)
fit_glm <- glm(NB ~ FORMULE + TYPE_RESIDENCE + SITUATION_JURIDIQUE + OBJETS_DE_VALEUR + as.factor(VALEUR_DES_BIENS) + as.factor(NB_PIECES) + REGION + as.factor(NBSIN_TYPE1_AN1) + as.factor(NBSIN_TYPE1_AN3) + as.factor(ANNEE),
data=df_train, offset=log(EXPO), family=quasipoisson())
summary(fit_glm)
preprocess<- function(dt) {
res <- dt %>%
mutate(
NB_PIECES = ifelse(is.na(NB_PIECES), 2, NB_PIECES), #2 est le mode de NB_PIECES
NBSIN_TYPE1_AN1 = ifelse(NBSIN_TYPE1_AN1==0,0,1), #On regroupe les modalités non stables dans le temps
NBSIN_TYPE1_AN3 = ifelse(NBSIN_TYPE1_AN3==0,0,1), #On regroupe les modalités non stables dans le temps
REGION =  gsub('[0-9]', '', ZONIER), #création de région
OFFSET = log(EXPO) # création d'une variable d'offset qui servira pour le gbm
) %>%
select(-c('X', 'TYPE_HABITATION', 'NIVEAU_JURIDIQUE', 'NBSIN_TYPE1_AN2', 'NBSIN_TYPE2_AN1', 'NBSIN_TYPE2_AN2', 'NBSIN_TYPE2_AN3'  )) %>% # On supprime les variables sans lien stable dans le temps
relocate('id', 'EXPO', 'FORMULE', 'TYPE_RESIDENCE', 'SITUATION_JURIDIQUE', 'OBJETS_DE_VALEUR', 'VALEUR_DES_BIENS', 'NB_PIECES', 'ZONIER', 'REGION', 'NBSIN_TYPE1_AN1', 'NBSIN_TYPE1_AN3', 'ANNEE', 'NB', 'COUT' )
return(res)
}
df_train <- preprocess(mrh_train)
df_val <- preprocess(mrh_val)
df_test <- preprocess(mrh_test)
reg0 = glm(NB~1+offset(OFFSET),family=poisson,data=df_train)
summary(reg0)
fit_glm <- glm(NB ~ FORMULE + TYPE_RESIDENCE + SITUATION_JURIDIQUE + OBJETS_DE_VALEUR + as.factor(VALEUR_DES_BIENS) + as.factor(NB_PIECES) + REGION + as.factor(NBSIN_TYPE1_AN1) + as.factor(NBSIN_TYPE1_AN3) + as.factor(ANNEE),
data=df_train, offset=OFFSET, family=quasipoisson())
summary(fit_glm)
h2o.init(nthreads = -1)
h2o.init(nthreads = -1)
reg_bst_100 = h2o.gbm(y = 'NB', x = names(df_train),
distribution = "poisson",
offset_column = "OFFSET",
training_frame = as.h2o(df_train),
validation_frame = as.h2o(df_val),
ntrees = 100,
nfolds = 5,
seed = 1)
reg_bst_100 = h2o.gbm(y = 'NB', x = names(df_train),
distribution = "poisson",
offset_column = "OFFSET",
training_frame = as.h2o(df_train),
validation_frame = as.h2o(df_val),
ntrees = 100,
nfolds = 5,
seed = 1)
plot(reg_bst_100)
library(MASS)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
if (!require("here")){
install.packages("here")
library("here")
}
set_here
LoadPackage <- function (load.lib=c("")) {
install.lib<-load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib) install.packages(lib,dependencies=TRUE)
sapply(load.lib,require,character=TRUE)
}
LoadPackage(c('ggplot2', 'dplyr', 'formattable', 'DT', 'tidyr', 'caret', 'plotly', 'xgboost', 'flashlight', 'MetricsWeighted', 'corrplot', 'lsr', 'h2o'))
plot_obs<-function(df,feature,use_year=T) {
if (use_year) {
dt <-df %>%
group_by(df[[feature]], ANNEE, .drop=FALSE) %>%
summarise(Freq = sum(NB*EXPO)/sum(EXPO), nb_lignes = n(), EXPO=sum(EXPO) ,  pct_EXPO = sum(EXPO) /  sum(df$EXPO)) %>%
rename(feat = 'df[[feature]]')
} else {
dt <-df %>%
group_by(df[[feature]], .drop=FALSE) %>%
summarise(Freq = sum(NB*EXPO)/sum(EXPO), nb_lignes = n(), EXPO=sum(EXPO) ,  pct_EXPO = sum(EXPO) /  sum(df$EXPO)) %>%
rename(feat = 'df[[feature]]')
}
fig <-plot_ly()
fig <- fig %>% layout(title = paste0('Fréquence de sinistres par ', feature),
xaxis = list(title = feature),
yaxis = list(side = 'left', title = 'Exposition', showgrid = FALSE, zeroline = FALSE),
yaxis2 = list(side = 'right', overlaying = "y", title = 'Fréquence', showgrid = FALSE, zeroline = FALSE))
if (use_year) {
for (year in unique(dt$ANNEE)) {
dt_temp <- dt %>% filter(ANNEE==year)
fig <- fig %>% add_trace(
x= dt_temp$feat, y= dt_temp$EXPO, type = 'bar', name = paste0('Exposition_', year),
hovertemplate = 'Expo: %{y:.0f}<br>'
)
fig<- fig %>% add_trace(
x= dt_temp$feat, y= dt_temp$Freq, type = 'scatter', mode = 'lines', yaxis = 'y2', name= paste0('Fréquence_', year),
hovertemplate = 'Freq: %{y:.2%}<br>'
)
}
} else {
dt_temp <- dt
fig <- fig %>% add_trace(
x= dt_temp$feat, y= dt_temp$EXPO, type = 'bar', name = 'Exposition',
hovertemplate = 'Expo: %{y:.0f}<br>'
)
fig<- fig %>% add_trace(
x= dt_temp$feat, y= dt_temp$Freq, type = 'scatter', mode = 'lines', yaxis = 'y2', name= 'Fréquence',
hovertemplate = 'Freq: %{y:.2%}<br>'
)
}
return(fig)
}
resume <- function(df, feature) {
dt <-df %>%
group_by(df[[feature]], .drop=FALSE) %>%
summarise(Freq = sum(NB*EXPO)/sum(EXPO), nb_lignes = n(), EXPO=sum(EXPO) ,  pct_EXPO = sum(EXPO) /  sum(df$EXPO ))
colnames(dt)[1] <- feature
table<- formattable(dt,
align = c("l", rep("r", NCOL(dt) - 1)),
list(
Freq = percent,
nb_lignes= accounting,
EXPO = accounting,
pct_EXPO = percent
)
)
fig1<- plot_obs(df, feature, use_year = F)
fig2<- plot_obs(df, feature, use_year = T)
return(list(dt=dt, table=table, fig=fig1, figyr=fig2))
}
list.files(path=here('data', 'raw'))
expo_train = read.table(file = here('data', 'raw', 'expo_train.csv'), header=T, sep=',', dec='.', encoding = 'UTF-8', stringsAsFactors = F)
datatable(head(expo_train))
str(expo_train)
sin_train = read.table(file = here('data', 'raw', 'sin_train.csv'), header=T, sep=';', dec=',', encoding = 'UTF-8', stringsAsFactors = F)
datatable(head(sin_train))
str(sin_train)
dt <-sin_train %>%
group_by(NB) %>%
summarise(nb_lignes = n())
formattable(dt,
align=c('l','r'),
list(
nb_lignes= accounting
)
)
dt %>%
ggplot( aes(x=as.factor(NB), y=nb_lignes, fill=as.factor(NB))) +
geom_bar(stat='identity') +
ggtitle('Distribution NB')+
xlab('NB') +
ylab('nombre de lignes') +
labs(fill = 'NB')
mrh <- expo_train %>%
left_join(sin_train, by =c('id','ANNEE')) %>%
replace_na(list('NB'=0, 'COUT'=0))
set.seed(42)
trainIndex<- createDataPartition(mrh$NB>=0, p=.7, list=FALSE, time=1)
mrh_train<-mrh[trainIndex,]
mrh_test<-mrh[ -trainIndex,]
valIndex<- createDataPartition(mrh_test$NB>=0, p=.66, list=FALSE, time=1)
mrh_val<-mrh_test[ valIndex,]
mrh_test<-mrh_test[ -valIndex,]
tx <- sum(mrh_train$NB)/sum(mrh_train$EXPO)
print(paste0('taux de sinistre moyen annuel : ', round(tx * 100,2), '%'))
df = mrh_train
feature = 'FORMULE'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'TYPE_RESIDENCE'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'TYPE_HABITATION'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NB_PIECES'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'SITUATION_JURIDIQUE'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NIVEAU_JURIDIQUE'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'VALEUR_DES_BIENS'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'OBJETS_DE_VALEUR'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'ZONIER'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
test <- df %>% mutate(REGION = substr(ZONIER, 1,1))
feature = 'REGION'
res<-resume(test, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE1_AN1'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE1_AN2'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE1_AN3'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE2_AN1'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE2_AN2'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'NBSIN_TYPE2_AN3'
res<-resume(df, feature)
res$table
res$fig
res$figyr
df = mrh_train
feature = 'ANNEE'
res<-resume(df, feature)
res$table
res$fig
preprocess<- function(dt) {
res <- dt %>%
mutate(
NB_PIECES = ifelse(is.na(NB_PIECES), 2, NB_PIECES), #2 est le mode de NB_PIECES
NBSIN_TYPE1_AN1 = ifelse(NBSIN_TYPE1_AN1==0,0,1), #On regroupe les modalités non stables dans le temps
NBSIN_TYPE1_AN3 = ifelse(NBSIN_TYPE1_AN3==0,0,1), #On regroupe les modalités non stables dans le temps
REGION =  gsub('[0-9]', '', ZONIER), #création de région
OFFSET = log(EXPO) # création d'une variable d'offset qui servira pour le gbm
) %>%
select(-c('X', 'TYPE_HABITATION', 'NIVEAU_JURIDIQUE', 'NBSIN_TYPE1_AN2', 'NBSIN_TYPE2_AN1', 'NBSIN_TYPE2_AN2', 'NBSIN_TYPE2_AN3'  )) %>% # On supprime les variables sans lien stable dans le temps
relocate('id', 'EXPO', 'FORMULE', 'TYPE_RESIDENCE', 'SITUATION_JURIDIQUE', 'OBJETS_DE_VALEUR', 'VALEUR_DES_BIENS', 'NB_PIECES', 'ZONIER', 'REGION', 'NBSIN_TYPE1_AN1', 'NBSIN_TYPE1_AN3', 'ANNEE', 'NB', 'COUT' )
return(res)
}
df_train <- preprocess(mrh_train)
df_val <- preprocess(mrh_val)
df_test <- preprocess(mrh_test)
X_train <- df_train %>% select(-c('id', 'EXPO', 'NB', 'COUT'))
# Initialize empty matrix to store coefficients
empty_m <- matrix(ncol = length(X_train),
nrow = length(X_train),
dimnames = list(names(X_train),
names(X_train)))
# Function that accepts matrix for coefficients and data and returns a correlation matrix
calculate_cramer <- function(m, df) {
for (r in seq(nrow(m))){
for (c in seq(ncol(m))){
m[[r, c]] <- lsr::cramersV(X_train[[r]], X_train[[c]])
}
}
return(m)
}
cor_matrix <- calculate_cramer(empty_m ,X_train)
corrplot(cor_matrix)
reg0 = glm(NB~1+offset(OFFSET),family=poisson,data=df_train)
summary(reg0)
fit_glm_Diag <- data.frame(df_train,
link = predict(fit_glm, type = "link"),
fit = predict(fit_glm, type = "response"),
pearson = residuals(fit_glm, type = "pearson"),
resid = residuals(fit_glm, type = "response"),
residSqr = residuals(fit_glm, type = "response")^2
)
fit_glm <- glm(NB ~ FORMULE + TYPE_RESIDENCE + SITUATION_JURIDIQUE + OBJETS_DE_VALEUR + as.factor(VALEUR_DES_BIENS) + as.factor(NB_PIECES) + REGION + as.factor(NBSIN_TYPE1_AN1) + as.factor(NBSIN_TYPE1_AN3) + as.factor(ANNEE),
data=df_train, offset=OFFSET, family=quasipoisson())
summary(fit_glm)
fit_glm_Diag <- data.frame(df_train,
link = predict(fit_glm, type = "link"),
fit = predict(fit_glm, type = "response"),
pearson = residuals(fit_glm, type = "pearson"),
resid = residuals(fit_glm, type = "response"),
residSqr = residuals(fit_glm, type = "response")^2
)
fit_glm_Diag <- data.frame(df_train,
link = predict(fit_glm, type = "link"),
fit = predict(fit_glm, type = "response"),
pearson = residuals(fit_glm, type = "pearson"),
resid = residuals(fit_glm, type = "response"),
residSqr = residuals(fit_glm, type = "response")^2
)
ggplot(fit_glm_Diag, aes(x = fit, y = residSqr)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, size = 1) +
geom_smooth(se = F, size = 1) +
theme_bw()
fit_glm_Diag <- data.frame(df_train,
link = predict(fit_glm, type = "link"),
fit = predict(fit_glm, type = "response"),
pearson = residuals(fit_glm, type = "pearson"),
resid = residuals(fit_glm, type = "response"),
residSqr = residuals(fit_glm, type = "response")^2
)
ggplot(fit_glm_Diag, aes(x = fit, y = pearson)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, size = 1) +
geom_smooth(se = F, size = 1) +
theme_bw()
dat <- fit_glm_Diag %>%
select( fit, pearson) %>%
mutate(quantile = ntile(fit, 10)) %>%
select(quantile, fit, pearson) %>%
mutate(agg = mean(pearson))
View(dat)
dat <- fit_glm_Diag %>%
select( fit, pearson) %>%
mutate(quantile = ntile(fit, 10)) %>%
group_by(quantile) %>%
summarize(mean_fit = mean(fit, na.rm = TRUE), mean_pearson = mean(pearson, na.rm = TRUE))
dat <- fit_glm_Diag %>%
select( fit, pearson) %>%
mutate(quantile = ntile(fit, 10)) %>%
group_by(quantile) %>%
summarize(mean_fit = mean(fit, na.rm = TRUE), mean_pearson = mean(pearson, na.rm = TRUE))
ggplot(dat, aes(x = mean_fit, y = mean_pearson)) +
geom_point()
dat <- fit_glm_Diag %>%
select( fit, pearson) %>%
mutate(quantile = ntile(fit, 100)) %>%
group_by(quantile) %>%
summarize(mean_fit = mean(fit, na.rm = TRUE), mean_pearson = mean(pearson, na.rm = TRUE))
ggplot(dat, aes(x = mean_fit, y = mean_pearson)) +
geom_point()
dat <- fit_glm_Diag %>%
select( fit, pearson) %>%
mutate(quantile = ntile(fit, 200)) %>%
group_by(quantile) %>%
summarize(mean_fit = mean(fit, na.rm = TRUE), mean_pearson = mean(pearson, na.rm = TRUE))
ggplot(dat, aes(x = mean_fit, y = mean_pearson)) +
geom_point()
dat <- fit_glm_Diag %>%
select( fit, pearson) %>%
mutate(quantile = ntile(fit, 200)) %>%
group_by(quantile) %>%
summarize(mean_fit = mean(fit, na.rm = TRUE), mean_pearson = mean(pearson, na.rm = TRUE))
ggplot(dat, aes(x = mean_fit, y = mean_pearson)) +
geom_point() +
geom_abline(intercept = 0, slope = 0, size = 1, color="red")
dat <- fit_glm_Diag %>%
select( fit, pearson) %>%
mutate(quantile = ntile(fit, 150)) %>%
group_by(quantile) %>%
summarize(mean_fit = mean(fit, na.rm = TRUE), mean_pearson = mean(pearson, na.rm = TRUE))
ggplot(dat, aes(x = mean_fit, y = mean_pearson)) +
geom_point() +
geom_abline(intercept = 0, slope = 0, size = 1, color="red")
fit_glm_Diag <- data.frame(df_train,
link = predict(fit_glm, type = "link"),
fit = predict(fit_glm, type = "response"),
pearson = residuals(fit_glm, type = "pearson"),
resid = residuals(fit_glm, type = "response"),
residSqr = residuals(fit_glm, type = "response")^2
)
dat <- fit_glm_Diag %>%
select( fit, pearson) %>%
mutate(quantile = ntile(fit, 150)) %>%
group_by(quantile) %>%
summarize(mean_fit = mean(fit, na.rm = TRUE), mean_pearson = mean(pearson, na.rm = TRUE))
ggplot(dat, aes(x = mean_fit, y = mean_pearson)) +
geom_point() +
geom_abline(intercept = 0, slope = 0, size = 1, color="red") +
geom_tile("Rédidus de Pearson aggrégés")
dat <- fit_glm_Diag %>%
select( fit, pearson) %>%
mutate(quantile = ntile(fit, 150)) %>%
group_by(quantile) %>%
summarize(mean_fit = mean(fit, na.rm = TRUE), mean_pearson = mean(pearson, na.rm = TRUE))
ggplot(dat, aes(x = mean_fit, y = mean_pearson)) +
geom_point() +
geom_abline(intercept = 0, slope = 0, size = 1, color="red") +
geom_tile("Rédidus de Pearson aggrégés")
dat <- fit_glm_Diag %>%
select( fit, pearson) %>%
mutate(quantile = ntile(fit, 150)) %>%
group_by(quantile) %>%
summarize(mean_fit = mean(fit, na.rm = TRUE), mean_pearson = mean(pearson, na.rm = TRUE))
ggplot(dat, aes(x = mean_fit, y = mean_pearson)) +
geom_point() +
geom_abline(intercept = 0, slope = 0, size = 1, color="red") +
ggtile("Rédidus de Pearson aggrégés")
dat <- fit_glm_Diag %>%
select( fit, pearson) %>%
mutate(quantile = ntile(fit, 150)) %>%
group_by(quantile) %>%
summarize(mean_fit = mean(fit, na.rm = TRUE), mean_pearson = mean(pearson, na.rm = TRUE))
ggplot(dat, aes(x = mean_fit, y = mean_pearson)) +
geom_point() +
geom_abline(intercept = 0, slope = 0, size = 1, color="red") +
ggtitle("Rédidus de Pearson aggrégés")

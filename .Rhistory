LoadPackage <- function (load.lib=c("")) {
install.lib<-load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib) install.packages(lib,dependencies=TRUE)
sapply(load.lib,require,character=TRUE)
}
LoadPackage(c('ggplot2', 'dplyr', 'formattable', 'DT', 'tidyr', 'caret', 'plotly', 'h2o', 'xgboost'))
x <- c('FORMULE', 'TYPE_RESIDENCE', 'SITUATION_JURIDIQUE','OBJETS_DE_VALEUR', 'VALEUR_DES_BIENS', 'NB_PIECES', 'REGION', 'NBSIN_TYPE1_AN1', 'NBSIN_TYPE1_AN3', 'ANNEE')
y <- 'NB'
w <- 'EXPO'
# Input maker
prep_xgb <- function(dat, x) {
data.matrix(dat[, x, drop = FALSE])
}
# Data interface to XGBoost
dtrain <- xgb.DMatrix(
prep_xgb(df_train, x),
label = df_train[[y]],
weight = df_train[[w]]
)
# Parameters chosen by 5-fold grouped CV
params_freq <- list(
learning_rate = 0.2,
max_depth = 5,
alpha = 3,
lambda = 0.5,
max_delta_step = 2,
min_split_loss = 0,
#  monotone_constraints = c(0,-1,0,0,0,0,0),
#  interaction_constraints = list(4, c(0, 1, 2, 3, 5, 6)),
colsample_bytree = 1,
subsample = 0.9
)
# Fit
set.seed(1)
fit_xgb <- xgb.train(
params_freq,
data = df_train,
nrounds = 580,
objective = "count:poisson",
watchlist = list(train = df_train),
print_every_n = 100
)
# Input maker
prep_xgb <- function(dat, x) {
data.matrix(dat[, x, drop = FALSE])
}
# Data interface to XGBoost
dtrain <- xgb.DMatrix(
prep_xgb(df_train, x),
label = df_train[[y]],
weight = df_train[[w]]
)
# Parameters chosen by 5-fold grouped CV
params_freq <- list(
learning_rate = 0.2,
max_depth = 5,
alpha = 3,
lambda = 0.5,
max_delta_step = 2,
min_split_loss = 0,
#  monotone_constraints = c(0,-1,0,0,0,0,0),
#  interaction_constraints = list(4, c(0, 1, 2, 3, 5, 6)),
colsample_bytree = 1,
subsample = 0.9
)
# Fit
set.seed(1)
fit_xgb <- xgb.train(
params_freq,
data = dtrain,
nrounds = 580,
objective = "count:poisson",
watchlist = list(train = df_train),
print_every_n = 100
)
# Input maker
prep_xgb <- function(dat, x) {
data.matrix(dat[, x, drop = FALSE])
}
# Data interface to XGBoost
dtrain <- xgb.DMatrix(
prep_xgb(df_train, x),
label = df_train[[y]],
weight = df_train[[w]]
)
# Parameters chosen by 5-fold grouped CV
params_freq <- list(
learning_rate = 0.2,
max_depth = 5,
alpha = 3,
lambda = 0.5,
max_delta_step = 2,
min_split_loss = 0,
#  monotone_constraints = c(0,-1,0,0,0,0,0),
#  interaction_constraints = list(4, c(0, 1, 2, 3, 5, 6)),
colsample_bytree = 1,
subsample = 0.9
)
# Fit
set.seed(1)
fit_xgb <- xgb.train(
params_freq,
data = dtrain,
nrounds = 580,
objective = "count:poisson",
watchlist = list(train = dtrain),
print_every_n = 100
)
xgb.save(fit_xgb, "xgb.model")
fit_xgb <- xgb.load("xgb.model")
if (!require("here")){
install.packages("here")
library("here")
}
set_here
LoadPackage <- function (load.lib=c("")) {
install.lib<-load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib) install.packages(lib,dependencies=TRUE)
sapply(load.lib,require,character=TRUE)
}
LoadPackage(c('ggplot2', 'dplyr', 'formattable', 'DT', 'tidyr', 'caret', 'plotly', 'xgboost', 'flashlight'))
fit_glm <- glm(NB ~ FORMULE + TYPE_RESIDENCE + SITUATION_JURIDIQUE + OBJETS_DE_VALEUR + as.factor(VALEUR_DES_BIENS) + as.factor(NB_PIECES) + REGION + as.factor(NBSIN_TYPE1_AN1) + as.factor(NBSIN_TYPE1_AN3) + as.factor(ANNEE),
data=df_train, offset=log(EXPO), family=poisson())
summary(fit_glm)
plot(fit_glm)
fl_glm <- flashlight(
model = fit_glm, label = "GLM",
predict_function = function(fit, X) predict(fit, X, type = "response")
)
fl_glm <- flashlight(
model = fit_glm, label = "GLM",
predict_function = function(fit, X) predict(fit, X, type = "response")
)
fl_xgb <- flashlight(
model = fit_xgb, label = "XGBoost",
predict_function = function(fit, X) predict(fit, prep_xgb(X, x))
)
# Combine them and add common elements like reference data
metrics <- list(`Average deviance` = deviance_poisson,
`Relative deviance reduction` = r_squared_poisson)
if (!require("here")){
install.packages("here")
library("here")
}
set_here
LoadPackage <- function (load.lib=c("")) {
install.lib<-load.lib[!load.lib %in% installed.packages()]
for(lib in install.lib) install.packages(lib,dependencies=TRUE)
sapply(load.lib,require,character=TRUE)
}
LoadPackage(c('ggplot2', 'dplyr', 'formattable', 'DT', 'tidyr', 'caret', 'plotly', 'xgboost', 'flashlight', 'MetricsWeighted'))
fl_glm <- flashlight(
model = fit_glm, label = "GLM",
predict_function = function(fit, X) predict(fit, X, type = "response")
)
fl_xgb <- flashlight(
model = fit_xgb, label = "XGBoost",
predict_function = function(fit, X) predict(fit, prep_xgb(X, x))
)
# Combine them and add common elements like reference data
metrics <- list(`Average deviance` = deviance_poisson,
`Relative deviance reduction` = r_squared_poisson)
fls <- multiflashlight(list(fl_glm, fl_nn, fl_xgb), data = test,
y = y, w = w, metrics = metrics)
fl_glm <- flashlight(
model = fit_glm, label = "GLM",
predict_function = function(fit, X) predict(fit, X, type = "response")
)
fl_xgb <- flashlight(
model = fit_xgb, label = "XGBoost",
predict_function = function(fit, X) predict(fit, prep_xgb(X, x))
)
# Combine them and add common elements like reference data
metrics <- list(`Average deviance` = deviance_poisson,
`Relative deviance reduction` = r_squared_poisson)
fls <- multiflashlight(list(fl_glm, fl_xgb), data = test,
y = y, w = w, metrics = metrics)
# Version on canonical scale
fls_log <- multiflashlight(fls, linkinv = log)
fillc <- "#E69F00"
perf <- light_performance(fls)
fl_glm <- flashlight(
model = fit_glm, label = "GLM",
predict_function = function(fit, X) predict(fit, X, type = "response")
)
fl_xgb <- flashlight(
model = fit_xgb, label = "XGBoost",
predict_function = function(fit, X) predict(fit, prep_xgb(X, x))
)
# Combine them and add common elements like reference data
metrics <- list(`Average deviance` = deviance_poisson,
`Relative deviance reduction` = r_squared_poisson)
fls <- multiflashlight(list(fl_glm, fl_xgb), data = df_test,
y = y, w = w, metrics = metrics)
# Version on canonical scale
fls_log <- multiflashlight(fls, linkinv = log)
fillc <- "#E69F00"
perf <- light_performance(fls)
fl_glm <- flashlight(
model = fit_glm, label = "GLM",
predict_function = function(fit, X) predict(fit, X, type = "response")
)
fl_xgb <- flashlight(
model = fit_xgb, label = "XGBoost",
predict_function = function(fit, X) predict(fit, prep_xgb(X, x))
)
# Combine them and add common elements like reference data
metrics <- list(`Average deviance` = deviance_poisson,
`Relative deviance reduction` = r_squared_poisson)
fls <- multiflashlight(list(fl_glm, fl_xgb), data = df_val,
y = y, w = w, metrics = metrics)
# Version on canonical scale
fls_log <- multiflashlight(fls, linkinv = log)
fillc <- "#E69F00"
perf <- light_performance(fls)
View(fls_log)
View(fls_log)
View(fl_glm)
View(fls)
imp <- light_importance(fls, v = x)
fit_glm <- glm(NB ~ FORMULE + TYPE_RESIDENCE + SITUATION_JURIDIQUE + OBJETS_DE_VALEUR + as.factor(VALEUR_DES_BIENS) + as.factor(NB_PIECES) + REGION + as.factor(NBSIN_TYPE1_AN1) + as.factor(NBSIN_TYPE1_AN3) + as.factor(ANNEE),
data=df_train, offset=log(EXPO), family=quasipoisson()())
fit_glm <- glm(NB ~ FORMULE + TYPE_RESIDENCE + SITUATION_JURIDIQUE + OBJETS_DE_VALEUR + as.factor(VALEUR_DES_BIENS) + as.factor(NB_PIECES) + REGION + as.factor(NBSIN_TYPE1_AN1) + as.factor(NBSIN_TYPE1_AN3) + as.factor(ANNEE),
data=df_train, offset=log(EXPO), family=quasipoisson())
summary(fit_glm)
plot(fit_glm)
fl_glm <- flashlight(
model = fit_glm, label = "GLM",
predict_function = function(fit, X) predict(fit, X, type = "response")
)
fl_xgb <- flashlight(
model = fit_xgb, label = "XGBoost",
predict_function = function(fit, X) predict(fit, prep_xgb(X, x))
)
# Combine them and add common elements like reference data
metrics <- list(`Average deviance` = deviance_poisson,
`Relative deviance reduction` = r_squared_poisson)
fls <- multiflashlight(list(fl_glm, fl_xgb), data = df_val,
y = y, w = w, metrics = metrics)
# Version on canonical scale
fls_log <- multiflashlight(fls, linkinv = log)
fl_glm <- flashlight(
model = fit_glm, label = "GLM",
predict_function = function(fit, X) predict(fit, X, type = "response")
)
fl_xgb <- flashlight(
model = fit_xgb, label = "XGBoost",
predict_function = function(fit, X) predict(fit, prep_xgb(X, x))
)
# Combine them and add common elements like reference data
metrics <- list(`Average deviance` = deviance_poisson,
`Relative deviance reduction` = r_squared_poisson)
fls <- multiflashlight(list(fl_glm, fl_xgb), data = df_val,
y = y, w = w, metrics = metrics)
# Version on canonical scale
fls_log <- multiflashlight(fls, linkinv = log)
fillc <- "#E69F00"
perf <- light_performance(fls)
predict(fit_glm, df_val, type = "response")
View(df_val)
preprocess<- function(dt) {
res <- dt %>%
mutate(
NB_PIECES = ifelse(is.na(NB_PIECES), mode(NB_PIECES), NB_PIECES),
NBSIN_TYPE1_AN1 = ifelse(NBSIN_TYPE1_AN1==0,0,1), #On regroupe les modalités non stables dans le temps
NBSIN_TYPE1_AN3 = ifelse(NBSIN_TYPE1_AN3==0,0,1), #On regroupe les modalités non stables dans le temps
REGION =  gsub('[0-9]', '', ZONIER) #création de région
) %>%
select(-c('X', 'TYPE_HABITATION', 'NIVEAU_JURIDIQUE', 'NBSIN_TYPE1_AN2', 'NBSIN_TYPE2_AN1', 'NBSIN_TYPE2_AN2', 'NBSIN_TYPE2_AN3'  )) %>% # On supprime les variables sans lien stable dans le temps
relocate('id', 'EXPO', 'FORMULE', 'TYPE_RESIDENCE', 'SITUATION_JURIDIQUE', 'OBJETS_DE_VALEUR', 'VALEUR_DES_BIENS', 'NB_PIECES', 'ZONIER', 'REGION', 'NBSIN_TYPE1_AN1', 'NBSIN_TYPE1_AN3', 'ANNEE', 'NB', 'COUT' )
return(res)
}
df_train <- preprocess(mrh_train)
df_val <- preprocess(mrh_val)
df_test <- preprocess(mrh_test)
preprocess<- function(dt) {
res <- dt %>%
mutate(
NB_PIECES = ifelse(is.na(NB_PIECES), 2, NB_PIECES), #2 est le mode de NB_PIECES
NBSIN_TYPE1_AN1 = ifelse(NBSIN_TYPE1_AN1==0,0,1), #On regroupe les modalités non stables dans le temps
NBSIN_TYPE1_AN3 = ifelse(NBSIN_TYPE1_AN3==0,0,1), #On regroupe les modalités non stables dans le temps
REGION =  gsub('[0-9]', '', ZONIER) #création de région
) %>%
select(-c('X', 'TYPE_HABITATION', 'NIVEAU_JURIDIQUE', 'NBSIN_TYPE1_AN2', 'NBSIN_TYPE2_AN1', 'NBSIN_TYPE2_AN2', 'NBSIN_TYPE2_AN3'  )) %>% # On supprime les variables sans lien stable dans le temps
relocate('id', 'EXPO', 'FORMULE', 'TYPE_RESIDENCE', 'SITUATION_JURIDIQUE', 'OBJETS_DE_VALEUR', 'VALEUR_DES_BIENS', 'NB_PIECES', 'ZONIER', 'REGION', 'NBSIN_TYPE1_AN1', 'NBSIN_TYPE1_AN3', 'ANNEE', 'NB', 'COUT' )
return(res)
}
df_train <- preprocess(mrh_train)
df_val <- preprocess(mrh_val)
df_test <- preprocess(mrh_test)
View(mrh_val)
reg0 = glm(NB~1+offset(log(EXPO)),family=poisson,data=df_train)
summary(reg0)
plot(reg0)
reg0 = glm(NB~1+offset(log(EXPO)),family=poisson,data=df_train)
summary(reg0)
plot(reg0)
fit_glm <- glm(NB ~ FORMULE + TYPE_RESIDENCE + SITUATION_JURIDIQUE + OBJETS_DE_VALEUR + as.factor(VALEUR_DES_BIENS) + as.factor(NB_PIECES) + REGION + as.factor(NBSIN_TYPE1_AN1) + as.factor(NBSIN_TYPE1_AN3) + as.factor(ANNEE),
data=df_train, offset=log(EXPO), family=quasipoisson())
summary(fit_glm)
plot(fit_glm)
x <- c('FORMULE', 'TYPE_RESIDENCE', 'SITUATION_JURIDIQUE','OBJETS_DE_VALEUR', 'VALEUR_DES_BIENS', 'NB_PIECES', 'REGION', 'NBSIN_TYPE1_AN1', 'NBSIN_TYPE1_AN3', 'ANNEE')
y <- 'NB'
w <- 'EXPO'
# Input maker
prep_xgb <- function(dat, x) {
data.matrix(dat[, x, drop = FALSE])
}
# Data interface to XGBoost
dtrain <- xgb.DMatrix(
prep_xgb(df_train, x),
label = df_train[[y]],
weight = df_train[[w]]
)
# Parameters chosen by 5-fold grouped CV
params_freq <- list(
learning_rate = 0.2,
max_depth = 5,
alpha = 3,
lambda = 0.5,
max_delta_step = 2,
min_split_loss = 0,
#  monotone_constraints = c(0,-1,0,0,0,0,0),
#  interaction_constraints = list(4, c(0, 1, 2, 3, 5, 6)),
colsample_bytree = 1,
subsample = 0.9
)
# Fit
set.seed(1)
fit_xgb <- xgb.train(
params_freq,
data = dtrain,
nrounds = 580,
objective = "count:poisson",
watchlist = list(train = dtrain),
print_every_n = 100
)
View(df_test)
# Save and load model
xgb.save(fit_xgb, "xgb.model")
fit_xgb <- xgb.load("xgb.model")
fl_glm <- flashlight(
model = fit_glm, label = "GLM",
predict_function = function(fit, X) predict(fit, X, type = "response")
)
fl_xgb <- flashlight(
model = fit_xgb, label = "XGBoost",
predict_function = function(fit, X) predict(fit, prep_xgb(X, x))
)
# Combine them and add common elements like reference data
metrics <- list(`Average deviance` = deviance_poisson,
`Relative deviance reduction` = r_squared_poisson)
fls <- multiflashlight(list(fl_glm, fl_xgb), data = df_val,
y = y, w = w, metrics = metrics)
# Version on canonical scale
fls_log <- multiflashlight(fls, linkinv = log)
fillc <- "#E69F00"
perf <- light_performance(fls)
perf
plot(perf, geom = "point") +
labs(x = element_blank(), y = element_blank())
imp <- light_importance(fls, v = x)
plot(imp, fill = fillc, color = "black")
plot(light_profile(fls, v = "VALEUR_DES_BIENS"))
plot(light_profile(fls, v = "NB_PIECES"))
plot(light_profile(fls, v = "TYPE_RESIDENCE"))
# Average predicted versus covariable
plot(light_profile(fls, v = "NB_PIECES", type = "predicted"))
# Average residual versus covariable
plot(light_profile(fls, v = "NB_PIECES", type = "residual")) +
geom_hline(yintercept = 0)
# Average response versus covariable
plot(light_profile(fls, v = "NB_PIECES", type = "response"))
eff_DrivAge <- light_effects(fls, v = "NB_PIECES", counts_weighted = TRUE)
p <- plot(eff_DrivAge, show_points = FALSE)
plot_counts(p, eff_DrivAge, alpha = 0.3)
eff_DrivAge <- light_effects(fls, v = "NB_PIECES", counts_weighted = TRUE)
p <- plot(eff_DrivAge, show_points = FALSE)
plot_counts(p, eff_DrivAge, alpha = 0.3)
interact_rel <- light_interaction(
fls_log,
v = most_important(imp, 4),
take_sqrt = FALSE,
pairwise = TRUE,
use_linkinv = TRUE,
seed = 61
)
plot(interact_rel, color = "black", fill = fillc, rotate_x = TRUE)
interact_abs <- light_interaction(
fls_log,
v = most_important(imp, 4),
normalize = FALSE,
pairwise = TRUE,
use_linkinv = TRUE,
seed = 61
)
plot(interact_abs, color = "black", fill = fillc, rotate_x = TRUE)
# Strong interaction
pdp_NBPIECES_REGION <- light_profile(fls_log, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = sub_data)
# Strong interaction
pdp_NBPIECES_REGION <- light_profile(fls_log, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = df_val)
plot(pdp_NBPIECES_REGION)
# Weak interaction
pdp_TYPE_RESIDENCE_REGION <- light_profile(fls_log, v = "TYPE_RESIDENCE",
by = "REGION", pd_seed = 50, data = df_val)
plot(pdp_TYPE_RESIDENCE_REGION)
# Strong interaction
pdp_NBPIECES_REGION <- light_profile(fls_log, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = df_val)
plot(pdp_NBPIECES_REGION)
pdp_VALEURDESBIENS_REGION <- light_profile(fls_log, v = "VALEUR_DES_BIENS", by = "REGION",
pd_seed = 50, data = df_val)
plot(pdp_NBPIECES_REGION)
# Weak interaction
pdp_TYPE_RESIDENCE_REGION <- light_profile(fls_log, v = "TYPE_RESIDENCE",
by = "REGION", pd_seed = 50, data = df_val)
plot(pdp_TYPE_RESIDENCE_REGION)
# Strong interaction
pdp_NBPIECES_REGION <- light_profile(fls_log, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = df_val)
plot(pdp_NBPIECES_REGION)
pdp_VALEURDESBIENS_REGION <- light_profile(fls_log, v = "VALEUR_DES_BIENS", by = "REGION",
pd_seed = 50, data = df_val)
plot(pdp_VALEURDESBIENS_REGION)
# Weak interaction
pdp_TYPE_RESIDENCE_REGION <- light_profile(fls_log, v = "TYPE_RESIDENCE",
by = "REGION", pd_seed = 50, data = df_val)
plot(pdp_TYPE_RESIDENCE_REGION)
# Strong interaction
pdp_NBPIECES_REGION <- light_profile(fls_log, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = df_val)
plot(pdp_NBPIECES_REGION)
pdp_VALEURDESBIENS_REGION <- light_profile(fls_log, v = "VALEUR_DES_BIENS", by = "REGION",
pd_seed = 50, data = df_val, counts_weighted=TRUE)
plot(pdp_VALEURDESBIENS_REGION)
# Weak interaction
pdp_TYPE_RESIDENCE_REGION <- light_profile(fls_log, v = "TYPE_RESIDENCE",
by = "REGION", pd_seed = 50, data = df_val)
plot(pdp_TYPE_RESIDENCE_REGION)
# Strong interaction
pdp_NBPIECES_REGION <- light_profile(fls_log, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = df_val, counts_weighted=TRUE)
plot(pdp_NBPIECES_REGION)
pdp_VALEURDESBIENS_REGION <- light_profile(fls_log, v = "VALEUR_DES_BIENS", by = "REGION",
pd_seed = 50, data = df_val, counts_weighted=TRUE)
plot(pdp_VALEURDESBIENS_REGION)
# Weak interaction
pdp_TYPE_RESIDENCE_REGION <- light_profile(fls_log, v = "TYPE_RESIDENCE",
by = "REGION", pd_seed = 50, data = df_val, counts_weighted=TRUE)
plot(pdp_TYPE_RESIDENCE_REGION)
# Strong interaction
# p <- plot(eff_DrivAge, show_points = FALSE)
# plot_counts(p, eff_DrivAge, alpha = 0.3)
pdp_NBPIECES_REGION <- light_profile(fls_log, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = df_val, counts_weighted=TRUE)
p <- lot(pdp_NBPIECES_REGION, show_points = FALSE)
# Strong interaction
# p <- plot(eff_DrivAge, show_points = FALSE)
# plot_counts(p, eff_DrivAge, alpha = 0.3)
pdp_NBPIECES_REGION <- light_profile(fls_log, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = df_val, counts_weighted=TRUE)
p <- plot(pdp_NBPIECES_REGION, show_points = FALSE)
plot_counts(p, pdp_NBPIECES_REGION, alpha = 0.3)
# Strong interaction
# p <- plot(eff_DrivAge, show_points = FALSE)
# plot_counts(p, eff_DrivAge, alpha = 0.3)
pdp_NBPIECES_REGION <- light_effects(fls_log, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = df_val, counts_weighted=TRUE)
p <- plot(pdp_NBPIECES_REGION, show_points = FALSE)
# Strong interaction
# p <- plot(eff_DrivAge, show_points = FALSE)
# plot_counts(p, eff_DrivAge, alpha = 0.3)
pdp_NBPIECES_REGION <- light_effects(fls, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = df_val, counts_weighted=TRUE)
p <- plot(pdp_NBPIECES_REGION, show_points = FALSE)
# Strong interaction
# p <- plot(eff_DrivAge, show_points = FALSE)
# plot_counts(p, eff_DrivAge, alpha = 0.3)
pdp_NBPIECES_REGION <- light_profile(fls_log, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = df_val, counts_weighted=TRUE)
p <- plot(pdp_NBPIECES_REGION, show_points = FALSE)
plot_counts(p, pdp_NBPIECES_REGION, alpha = 0.3)
# Strong interaction
# p <- plot(eff_DrivAge, show_points = FALSE)
# plot_counts(p, eff_DrivAge, alpha = 0.3)
pdp_NBPIECES_REGION <- light_profile(fls_log, v = "NB_PIECES", by = "REGION",
pd_seed = 50, data = df_val, counts_weighted=TRUE)
p <- plot(pdp_NBPIECES_REGION, show_points = FALSE)
pdp_count <- light_effects(fls, v = "NB_PIECES")
plot_counts(p, pdp_count, alpha = 0.3)
pdp_VALEURDESBIENS_REGION <- light_profile(fls_log, v = "VALEUR_DES_BIENS", by = "REGION",
pd_seed = 50, data = df_val, counts_weighted=TRUE)
plot(pdp_VALEURDESBIENS_REGION)
# Weak interaction
pdp_TYPE_RESIDENCE_REGION <- light_profile(fls_log, v = "TYPE_RESIDENCE",
by = "REGION", pd_seed = 50, data = df_val, counts_weighted=TRUE)
plot(pdp_TYPE_RESIDENCE_REGION)
View(fls)
# Average predicted versus covariable
plot(light_profile(fls, v = "NB_PIECES", type = "predicted"))
# Average residual versus covariable
plot(light_profile(fls, v = "NB_PIECES", type = "residual")) +
geom_hline(yintercept = 0)
# Average response versus covariable
plot(light_profile(fls, v = "NB_PIECES", type = "response"))
View(fl_glm)
fl_glm$predict_function(fit_glm, df_val)
summary(df_val$NB/df_val$EXPO)
summary(fl_glm$predict_function(fit_glm, df_val))
summary(fl_xgb$predict_function(fit_xgb, df_val))
